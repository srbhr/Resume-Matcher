SESSION_SECRET_KEY="a-secret-key"
SYNC_DATABASE_URL="sqlite:///./app.db"
ASYNC_DATABASE_URL="sqlite+aiosqlite:///./app.db"
PYTHONDONTWRITEBYTECODE=1
# If you use other providers besides ollama, you may also want to use the following settings:
# LLM_API_KEY="..."
# LLM_BASE_URL="..."
# EMBEDDING_API_KEY="..."
# EMBEDDING_BASE_URL="..."
LLM_PROVIDER="ollama"
# TODO: investigate other lightweight LLMs that can run on client hardware:
#       gemma3n:e4b
#       phi4-mini
#       deepseek-r1:7b
LL_MODEL="gemma3:4b"
EMBEDDING_PROVIDER="ollama"
# Historically we used "nomic-embed-text:137m-v1.5-fp16", but the following is much
# higher up on the HF MTEB leaderboard, and still fairly lightweight.
EMBEDDING_MODEL="dengcao/Qwen3-Embedding-0.6B:Q8_0"

#for gemini api 
#LLM_PROVIDER="llama_index.llms.google_genai.GoogleGenAI"
#LL_MODEL="gemini-1.5-flash"
#EMBEDDING_PROVIDER="llama_index.embeddings.google_genai.GoogleGenAIEmbedding"
# Historically we used "nomic-embed-text:137m-v1.5-fp16", but the following is much
# higher up on the HF MTEB leaderboard, and still fairly lightweight.
#EMBEDDING_MODEL="text-embedding-004"
#LLM_API_KEY="you_gemini_api_key"
#EMBEDDING_API_KEY="you_gemini_api_key"
#LLM_BASE_URL=""
#EMBEDDING_BASE_URL=""

