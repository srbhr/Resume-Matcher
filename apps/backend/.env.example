# LLM Provider Configuration
# Supported providers: openai, anthropic, openrouter, gemini, deepseek, ollama
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_API_KEY=sk-your-api-key-here

# For Ollama (local models)
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.2
# LLM_API_BASE=http://localhost:11434

# For OpenRouter
# LLM_PROVIDER=openrouter
# LLM_MODEL=anthropic/claude-3.5-sonnet
# LLM_API_KEY=sk-or-v1-your-key

# For Anthropic
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-5-sonnet-20241022
# LLM_API_KEY=sk-ant-your-key

# For Google Gemini
# LLM_PROVIDER=gemini
# LLM_MODEL=gemini/gemini-1.5-flash
# LLM_API_KEY=your-gemini-key

# For DeepSeek
# LLM_PROVIDER=deepseek
# LLM_MODEL=deepseek/deepseek-chat
# LLM_API_KEY=your-deepseek-key

# Server Configuration
HOST=0.0.0.0
PORT=8000
